get_ipython().run_line_magic("run", " fMRI_prestats0_general.ipynb")


# control results
key = random.sample(data.keys(), 1)
print(data[key[0]])
print(data["FED015"])


# set default data ouput for all FSL operations
fsl.FSLCommand.set_default_output_type('NIFTI_GZ')


# prepare the structural scans
# for usage in motion correction, normalisation etc.

structs = [i for sub in FEDs
           for i in data[sub]["files"]
           if re.match(r'.*(T1).*(?<=\d{14}).nii', i)]

# try different bets, starting with fsl_vbm parameters from custom bash script first
#fracs=["0."+str(i) for i in np.arange(20,80,5)]
# after visual inspection:
frac = "0.35"

# perform brain extraction
for file in structs:
    bet = pe.Node(fsl.BET(), name="bet")
    bet.inputs.in_file=file
    bet.inputs.out_file = f"{file.split('_', 1)[0]}_BETBf{str(frac[2:])}.nii"
    bet.inputs.outline = True
    bet.inputs.reduce_bias = True
    bet.inputs.frac = float(frac)
    bet.inputs.output_type = "NIFTI"
    # run it
    res=bet.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# control number of brain-extracted files
structs_bet = sorted([file for sub in FEDs
                      for file in data[sub]["files"]
                      if re.match(r'.*(T1_BET).*(?<!overlay)(?<!mask).nii', file)])

# control the file list
print(len(structs_bet))

# plot before-after comparison of BET
for sub in FEDs:
    for file in data[sub]["files"]:
        if re.match(r'.*(T1).*(?<=\d{14}).nii', file):
            plot_anat(file, title=f'{sub}: BET input', cut_coords=(10,10,10), display_mode='ortho',
                      dim=-1, draw_cross=False, annotate=False);
        elif re.match(r'.*(T1_BET).*(?<!overlay)(?<!mask).nii', file):
            plot_anat(file, title=f'{sub}: BET output', cut_coords=(10,10,10), display_mode='ortho',
                      dim=-1, draw_cross=False, annotate=False);


# define a function to get the index of the middle volume of a functional dataset
def getmiddlevolume_index(func):
    funcfile = func
    if isinstance(func, list):
        funcfile = func[0]
    _, _, _, timepoints = nb.load(funcfile).shape
    return int(timepoints / 2)  # int()rounds down


for i in raws:
    print(i)
    print(i.rsplit('/',2)[1],"   ",getmiddlevolume_index(i))


# MCFLIRT (6DFs) Motion correction -- 6 regressors in Level1 Model
# define input files
raws = sorted([i for sub in FEDs
               for i in data[sub]["files"]
               if re.match(r'.*(FMRI).*(?<=\d{14}).nii', i)])

# set up MCFLIRT node (parameters are based on simulation results -> Drobnjak thesis)
for img in raws:
    # set up node to extract the middle volume of a subject as reference for MCFLIRT
    middle_ref = pe.Node(fsl.ExtractROI(), name='middle_ref')
    middle_ref.inputs.in_file = img
    middle_ref.inputs.t_size = 1
    middle_ref.inputs.t_min = getmiddlevolume_index(img)
#    middle_ref.inputs.roi_file= f"{img.rsplit('_',2)[0]}_midvol.nii.gz"
    # run it
    res1 = middle_ref.run()
    # set up MCFLIRT node (parameters are based on simulation results -> Drobnjak thesis)
    mcflirt = pe.Node(fsl.MCFLIRT(), name="mcflirt")
    mcflirt.inputs.in_file = img
    mcflirt.inputs.cost = "normcorr"
    mcflirt.inputs.save_plots = True
    mcflirt.inputs.stages = 4
    mcflirt.inputs.ref_file = res1.outputs.roi_file
    mcflirt.inputs.out_file = f"{img.rsplit('_',2)[0]}_mc.nii.gz"
    # run it
    res2 = mcflirt.run()
    # print the results
    print(res2.outputs)

# update files
update_files()


# plot the estimated motion parameters (MCFLIRT parameter output)
# define input files
mcorrs = sorted([i for sub in FEDs
                 for i in data[sub]["files"]
                 if re.match(r'.*(FMRI).*(?<=mc).nii.gz$', i)])

# set up plotting node
for i in mcorrs:
    plotmotion = pe.Node(fsl.PlotMotionParams(), name='plotmotion')
    plotmotion.inputs.in_file = f"{i}.par"
    plotmotion.inputs.in_source = 'fsl'
    plotmotion.inputs.plot_type = 'displacement'
    # run it
    res = plotmotion.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# define motion parameter images
motpar_png = sorted([i for sub in FEDs
                     for i in data[sub]["files"]
                     if re.match(r'.*(FMRI).*(?<=gz_disp).png', i)])
# control length
print(len(motpar_png))

# print png files for the first seven subjects
for i in motpar_png[0:7]:
    mpar = mpl_img.imread(i)
    fig, ax = plt.subplots()
    plt.title(f"{i.split('/',3)[2]} mean displacement (mm):")
    plt.imshow(mpar)


# OPTIONAL!:
# Motion_outliers (extreme outliers) -- 1 regressor/outlier(might not all have the same effect^^) in Level1 Model

# set up MELODIC node
for i in mcorrs:
    mot_outlier = pe.Node(fsl.MotionOutliers(), name="mot_outlier")
    mot_outlier.inputs.in_file = i
    mot_outlier.inputs.no_motion_correction = True
    mot_outlier.inputs.out_file = f"{i[:-4]}_outliers.txt"
    mot_outlier.inputs.out_metric_values = f"{i[:-4]}_metrics.txt"
    mot_outlier.inputs.out_metric_plot = f"{i[:-4]}_metrics.png"
    # run it
    res = mot_outlier.run()
    # print the results
    print(res.outputs)

# update files
update_files()

# -> use rapidart as an alternative means for artefact correction at the very end of the preprocessing workflow -> FSLrec


# run MELODIC to extract Independent Components from functional data
# set up MELODIC node and run for 8 examples
for i in mcorrs[0:4] + mcorrs[-4:]:
    melodic = pe.Node(fsl.MELODIC(), name="melodic")
    melodic.inputs.in_files = i
    melodic.inputs.out_dir = f"{i.rsplit('/',1)[0]}/melodic_postmotcor"
    melodic.inputs.report = True
    # run it
    res = melodic.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# check that the local FSL 6.0.4 is giving you the same results to exclude version-based differences: DIFFERENT RESULTS!
# -> check suitability of ICA by inspecting your data
# do as pre-post inspection of the ICA in the 8 examples
# ONLY IF SUITED/CLASSIFIABLE:
# manually train FIX (20 subjects) then use the trained classifier to label artefact components in fMRI data
# use fsl_regfilt to regress out the artefacts and gain the motion-corrected fMRI data

# -> not suited! Too little expertise. Unfeasible. Revert to standard motion correction as done with MCFLIRT


# calculate the mean volume for each functional image
for i in mcorrs:
    meanfunc = pe.Node(fsl.maths.MeanImage(), name="meanfunc")
    meanfunc.inputs.in_file = i
    meanfunc.inputs.dimension = "T"
    meanfunc.inputs.out_file = f"{i.rsplit('.',2)[0]}_mean.nii.gz"
    # run it
    res=meanfunc.run()
    # print it
    print(res.outputs)

# update files
update_files()


# strip the skull from the mean volume to generate a functional mask
# define input files
means = sorted([i for sub in FEDs
               for i in data[sub]["files"]
               if re.match(r'.*(FMRI).*(?<=mc)_mean', i)])

# define a fractional intensity for thresholding (same as in structurals here)
frac = 0.35

for i in means[6:]:
    maskstrip = pe.Node(fsl.BET(), name="maskstrip")
    maskstrip.inputs.in_file = i
    maskstrip.inputs.no_output = True
    maskstrip.inputs.outline = True
    maskstrip.inputs.mask = True
    maskstrip.inputs.out_file = f"{i.rsplit('_',1)[0]}.nii.gz" # "_mask" suffix is affixed automatically
    maskstrip.inputs.frac = frac
    # run it
    res = maskstrip.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# mask the functional runs with the mask
# define input files
masks = sorted([i for sub in FEDs
               for i in data[sub]["files"]
               if re.match(r'.*(FMRI).*(?<=mc)_mask', i)])

for img, mask in zip(mcorrs, masks):
    maskfunc = pe.Node(fsl.ImageMaths(), name="maskfunc")
    maskfunc.inputs.in_file = img
    maskfunc.inputs.in_file2 = mask
    maskfunc.inputs.out_file = f"{img.rsplit('.',2)[0]}_masked.nii.gz"
    maskfunc.inputs.op_string = "-mas"
    # run it
    res = maskfunc.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# get the robust intensity range (ignore outer tales of the intensity distribution by 2% at each end) - this prevents outlier effects
# define input files
mcormasked = sorted([i for sub in FEDs
                    for i in data[sub]["files"]
                    if re.match(r'.*(FMRI).*(?<=mc)_masked.nii.gz$', i)])

for img in mcormasked:
    robintrange = pe.Node(fsl.ImageStats(), name="robintrange")
    robintrange.inputs.in_file = img
    robintrange.inputs.op_string = "-p 2 -p 98"
    # run it
    res = robintrange.run()
    # insert the robust intensity touple into the parameter dict for the present subject
    data[img.rsplit('/',2)[1]]["parameters"]["robintrange"] = res.outputs.out_stat
    # print the results
    print(res.outputs)


# define a function top obtain the thresholding op_string at 10% of the 98th percentile
def getthreshopstring(robintrange):
    return f'-thr {0.1 * robintrange[1]} -Tmin -bin'


# threshold the masked functionals at 10% of the 98th percentile (FEAT standard procedure)
for img in mcormasked:
    robintthresh = pe.Node(fsl.ImageMaths(), name="robinttresh")
    robintthresh.inputs.in_file = img
    robintthresh.inputs.out_data_type = "char"
    robintthresh.inputs.op_string = getthreshopstring(data[img.rsplit('/',2)[1]]["parameters"]["robintrange"])
    robintthresh.inputs.out_file = f"{img.rsplit('_',1)[0]}_robintthresh.nii.gz"
    # run it
    res = robintthresh.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# determine the median value of the motion corrected unmasked functional runs using the robust intensity range
# define input files
robintthreshs = sorted([i for sub in FEDs
                       for i in data[sub]["files"]
                       if re.match(r'.*(FMRI).*(?<=robintthresh).nii.gz$', i)])

for img, robintthresh in zip(mcorrs, robintthreshs):
    medianval = pe.Node(fsl.ImageStats(), name="medianval")
    medianval.inputs.in_file = img
    medianval.inputs.mask_file = robintthresh
    medianval.inputs.op_string = "-k %s -p 50"
    # run it
    res = medianval.run()
    # insert the median intensity value into the parameter dict for the present subject
    data[img.rsplit('/',2)[1]]["parameters"]["medianint"] = res.outputs.out_stat
    # print the results
    print(res.outputs)


# dilate the robust intensity threshold mask
for mask in robintthreshs:
    dilatemask= pe.Node(fsl.ImageMaths(), name="dilatemask")
    dilatemask.inputs.in_file= mask
    dilatemask.inputs.op_string= "-dilF"
    dilatemask.inputs.out_file= f"{mask.rsplit('.',2)[0]}_dil.nii.gz"
    # run it
    res=dilatemask.run()
    # print the results
    print(res.outputs)
    
# update files
update_files()


# mask the motion corrected functional runs with the undilated robust intensity threshold mask (dilated leaves skull!)
for img, mask in zip(mcorrs, robintthreshs):
    maskfunc2 = pe.Node(fsl.ImageMaths(), name="maskfunc2")
    maskfunc2.inputs.in_file = img
    maskfunc2.inputs.in_file2 = mask
    maskfunc2.inputs.out_file = f"{img.rsplit('.',2)[0]}-ri.nii.gz"
    maskfunc2.inputs.op_string = "-mas"
    # run it
    res = maskfunc2.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# calculate the mean image for each robust intensity thresholded functional image
# define input files
mcorrobint = sorted([i for sub in FEDs
                    for i in data[sub]["files"]
                    if re.match(r'.*(FMRI).*(?<=ri).nii.gz$', i)])

for img in mcorrobint:
    meanfunc2 = pe.Node(fsl.maths.MeanImage(), name="meanfunc2")
    meanfunc2.inputs.in_file = img
    meanfunc2.inputs.dimension = "T"
    meanfunc2.inputs.out_file = f"{img.rsplit('.', 2)[0]}_mean.nii.gz"
    # run it
    res = meanfunc2.run()
    # print it
    print(res.outputs)

# update files
update_files()


# merge mean images and median values into tuples = usans for each subject
# define input files
mcorrobint_means = sorted([i for sub in FEDs
                          for i in data[sub]["files"]
                          if re.match(r'.*(FMRI).*(?<=mc-ri)_mean.nii.gz$', i)])

medianvals = [data[sub]["parameters"]["medianint"]
              for sub in FEDs]  # don't sort^^

for mean, median in zip(mcorrobint_means, medianvals):
    data[mean.rsplit('/', 2)[1]]["parameters"]["usantuple"] = [mean, median]


# define function to get the brightness threshold for SUSAN at 75% median intensity (FSL FEAT default)
def getbtthresh(medianval):
    return 0.75 * medianval

# define a function to get the usans (brightness threshold plus mean functional mask) for SUSAN
def getusans(usantuple):
    return [tuple([usantuple[0], 0.75 * usantuple[1]])]


# smooth the data using SUSAN
for img in mcorrobint:
    # explore different degrees of smoothing
    for fwhm in [5.0, 8.0]:
        smooth = pe.Node(fsl.SUSAN(), name="smooth")
        smooth.inputs.in_file = img
        smooth.inputs.out_file = f"{img.rsplit('.', 2)[0]}-s{str(fwhm).split('.', 1)[0]}.nii.gz"
        smooth.inputs.brightness_threshold = getbtthresh(data[img.rsplit('/', 2)[1]]["parameters"]["medianint"])
        smooth.inputs.usans = getusans(data[img.rsplit('/', 2)[1]]["parameters"]["usantuple"])
        smooth.inputs.fwhm = fwhm
        # run it
        res = smooth.run()
        # print it
        print(res.outputs)

# update files
update_files()


# mask the smoothed functional runs with the undilated robust intensity threshold mask
# after visual inspection, we're going with 5mm fwhm for the present
# define input files
smoothed = sorted([i for sub in FEDs
                  for i in data[sub]["files"]
                  if re.match(r'.*(FMRI).*(?<=s)5.nii.gz$', i)])

for img, mask in zip(smoothed, robintthreshs):
    maskfunc3 = pe.Node(fsl.ImageMaths(), name="maskfunc3")
    maskfunc3.inputs.in_file = img
    maskfunc3.inputs.in_file2 = mask
    maskfunc3.inputs.out_file = f"{img.rsplit('.', 2)[0]}-m.nii.gz"
    maskfunc3.inputs.op_string = "-mas"
    # run it
    res = maskfunc3.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# define a function to get the scaling factor for intensity normalisation
def getintnormscale_opstring(medianval):
    return f'-mul {10000 / medianval}'


# Scale each volume of the run so that the median value of each run is set to 10000
# define input files
smoothed_masked = sorted([i for sub in FEDs
                         for i in data[sub]["files"]
                         if re.match(r'.*(FMRI).*(?<=s5)-m.nii.gz$', i)])

for img in smoothed_masked:
    intnorm = pe.Node(fsl.ImageMaths(), name="intnorm")
    intnorm.inputs.in_file = img
    intnorm.inputs.out_file = f"{img.split('.', 2)[0]}-in.nii.gz"
    intnorm.inputs.op_string = getintnormscale_opstring(data[img.rsplit('/', 2)[1]]["parameters"]["medianint"])
    # run it
    res = intnorm.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# look at the median of each run to check intensity normalisation (NOT equal to 10000 exactly)
# define input files
intnormed = sorted([i for sub in FEDs
                   for i in data[sub]["files"]
                   if re.match(r'.*(FMRI).*(?<=-m-in).nii.gz$', i)])

for img, mask in zip(intnormed, robintthreshs):
    medianval2 = pe.Node(fsl.ImageStats(), name="medianval2")
    medianval2.inputs.in_file = img
    medianval2.inputs.mask_file = mask
    medianval2.inputs.op_string = "-k %s -p 50"
    # run it
    res1 = medianval2.run()
    # calculate the corrective multiplier required to bring the median to a full 10000
    res2 = 10000 / res1.outputs.out_stat
    # print the results
    print("Global Median:   ", res1.outputs.out_stat, "Corrective Multiplier:   ", res2)
    print("\n\n")
    # repeat the intensity normalisation using the corrective multiplier
    intnorm2 = pe.Node(fsl.ImageMaths(), name="intnorm2")
    intnorm2.inputs.in_file = img
    intnorm2.inputs.out_file = f"{img.split('.',2)[0]}2x.nii.gz"
    intnorm2.inputs.op_string = f" -mul {res2}"
    # run it
    res3 = intnorm2.run()
    # print the results
    print(res3.outputs)

# update files
update_files()


# control success/usefulness of double intensity normalisation
# define input files
intnormed2x = sorted([i for sub in FEDs
                     for i in data[sub]["files"]
                     if re.match(r'.*(FMRI).*(?<=-m-in)2x.nii.gz$', i)])

for img, mask in zip(intnormed2x, robintthreshs):
    medianval3 = pe.Node(fsl.ImageStats(), name="medianval3")
    medianval3.inputs.in_file = img
    medianval3.inputs.mask_file = mask
    medianval3.inputs.op_string = "-k %s -p 50"
    # run it
    res = medianval3.run()
    # print the results
    print(res.outputs)


# define a function to get the highpass sigma for temporal highpass filtering
def gethighpasssigma_opstring(cutoff_seconds, TR):
    return f'-bptf {np.floor(cutoff_seconds / TR)} -1' # "-1" is the lowpass sigma


# set up the temporal highpass filtering 
for img in intnormed2x:
    highpassfilt = pe.Node(fsl.ImageMaths(), name="highpassfilt")
    highpassfilt.inputs.in_file = img
    highpassfilt.inputs.out_file = f"{img.split('.',2)[0]}-hp.nii.gz"
    # use FSL default cutoff in seconds for the present
    highpassfilt.inputs.op_string = gethighpasssigma_opstring(100, data[img.rsplit('/', 2)[1]]["parameters"]["EPI_RT"])
    # run it
    res = highpassfilt.run()
    # print the results
    print(res.outputs)

# update files
update_files()


# coregister the functional to the structural image via a 6DOF BBR and the structural to the MNI template via a 12DOF affine
# write only affine transform matrices and apply them before 2nd level analysis
# define input files
hpfiltered = sorted([i for sub in FEDs
                    for i in data[sub]["files"]
                    if re.match(r'.*(FMRI).*(?<=-hp).nii.gz$', i)])

# functional to structural
for func, struct in zip(hpfiltered[0:1], structs_bet[0:1]):
    flirt_fs = pe.Node(fsl.FLIRT(), name="flirt_fs")
    flirt_fs.inputs.in_file = func
    flirt_fs.inputs.reference = struct
    flirt_fs.inputs.cost_func = "bbr"
    flirt_fs.inputs.dof = 6
    flirt_fs.inputs.out_matrix_file = f"{func.rsplit('.', 2)[0]}_matrix"
    # run it
    res = flirt_fs.run()
    # print the results
    print(res.outputs)

# structural to MNI
#for struct in structs_bet:
    





# control inputs for artifact detection below, before using them
for img, realignpar, mask in zip(mcorrobint, motpars, robintthreshs_dil):
    print(img.rsplit('/', 2)[1])
    print(img)
    print(realignpar)
    print(mask)


# set up artifact detection
# define input files
motpars = sorted([i for sub in FEDs
                 for i in data[sub]["files"]
                 if re.match(r'.*(FMRI).*(?<=mc).nii.gz.par$', i)])

for img, realignpar, mask in zip(mcorrobint, motpars, robintthreshs_dil):
    artdetect = pe.Node(ra.ArtifactDetect(), name="artdetect")
    artdetect.inputs.realigned_files = img
    artdetect.inputs.realignment_parameters = realignpar
    artdetect.inputs.use_differences = [True, False]
    artdetect.inputs.use_norm = True
    artdetect.inputs.norm_threshold = 1
    artdetect.inputs.zintensity_threshold = 2  # 2 SDs define outliers well .....other threshold better?
    artdetect.inputs.parameter_source = 'FSL'
    artdetect.inputs.mask_type = 'file'
    artdetect.inputs.mask_file = mask
    # run it
    res = artdetect.run()
    # print the results
    print(res.outputs)

# update files
update_files()






