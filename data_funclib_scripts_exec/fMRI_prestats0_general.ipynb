{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather necessary pre-requisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import everything you need\n",
    "from nipype import Node, Workflow\n",
    "import nipype.interfaces.fsl as fsl\n",
    "#import nipype.interfaces.spm as spm\n",
    "#import nibabel as nb\n",
    "from nilearn.plotting import plot_anat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# activate inline magics\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os, operator, re, json, random\n",
    "from functools import reduce\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write update function for file list to data dictionary\n",
    "def update_files():\n",
    "    for sub in FEDs:\n",
    "        # collect image files from source dirs\n",
    "        files=sorted([os.path.join(subdir, content)\n",
    "                      for subdir in FED_dirs\n",
    "                      for content in os.listdir(subdir)\n",
    "                      if re.match(r'(.*.(nii|json))', content)])\n",
    "        # extend content\n",
    "        content=[file for file in files\n",
    "                 if re.match(fr'(.*{sub}.*)', file)]\n",
    "        # update files in data\n",
    "        data[sub][\"files\"]=content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data structure that holds all relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define base diectory for data, fMRI folder structure and FEDs\n",
    "scriptdatadir=\"/home/martin/FED/\"\n",
    "credentials=f\"{scriptdatadir}FED_Subject_Assignments.xlsx\"\n",
    "modelinfo=f\"{scriptdatadir}FED_Day_2_RAW_Coded_ALLCODESFIXED_Kontrolle_Truncated_Correct_and_Incorrect_3SDRemoved_46Fixed.xls\"\n",
    "\n",
    "basedir=\"/fMRI/\"\n",
    "FED_dirs=[os.path.join(basedir, FED) \n",
    "          for FED in os.listdir(basedir)\n",
    "          if os.path.isdir(os.path.join(basedir, FED))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect image files\n",
    "files=sorted([os.path.join(subdir, content)\n",
    "       for subdir in FED_dirs\n",
    "       for content in os.listdir(subdir)\n",
    "       if re.match(r'(.*.(nii|json))', content)])\n",
    "# create a dictionary storing all files/subject\n",
    "data={}\n",
    "for fed in FED_dirs:\n",
    "    ID=fed.rsplit('/', 1)[1]\n",
    "    # define partition for each subject\n",
    "    subject={\"files\":[], \"parameters\":{}}\n",
    "    content=[]\n",
    "    for file in files:\n",
    "        if re.match(fr'(.*{ID}.*)', file):\n",
    "            content.append(file)\n",
    "    subject[\"files\"].extend(content)\n",
    "    data[ID]=subject\n",
    "    \n",
    "# create shortcut to FEDs\n",
    "FEDs=sorted([key for key in data.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get relevant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject(s) missing!\n",
      "First line of list-alignment:   FED006 FED006 FED007\n",
      "Control relevant files!\n",
      "\n",
      "\n",
      " The following subjects where excluded from further analysis due to false file numbers or missing data:  \n",
      " EPI:  ['FED006'] T1:  ['FED006']\n"
     ]
    }
   ],
   "source": [
    "## define exclusion set for FEDs that do not meet the requirements\n",
    "#GRE_excluded=[]\n",
    "EPI_excluded=[]\n",
    "T1_excluded=[]\n",
    "\n",
    "## FED control\n",
    "for subject in FEDs:\n",
    "    # collect relevant files/FED for parameter extraction\n",
    "#    GREs=[file for file in data[subject][\"files\"]\n",
    "#           if re.match(r'(.*(_e1|_e2(?!_ph)).*.json)', file)]\n",
    "    EPIs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(FMRI).*.json)', file)]\n",
    "    T1s=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(T1_MPRAGE).*.json)', file)]\n",
    "\n",
    "    # control number of files\n",
    "    if len(EPIs) != 1:\n",
    "        print(subject, \"\\n\", f\"Not exactly one FMRI sequence to read out ({len(EPIs)}).... investigate\", \"\\n\")\n",
    "        EPI_excluded.append(subject)\n",
    "\n",
    "    if len(T1s) != 1:\n",
    "        print(subject, \"\\n\", f\"Not exactly one T1 sequence to read out ({len(T1)}).... investigate\", \"\\n\")\n",
    "        T1_excluded.append(subject)    \n",
    "\n",
    "    # There seem to be several omissions in the GRER_FIELD data -> investigate\n",
    "#    elif len(GREs) < 2:\n",
    "#        print(subject, \"\\n\", f\"Not enough GRE_FIELD sequences to read out ({len(GREs)}).... exclude/investigate\", \"\\n\")\n",
    "#        GRE_excluded.append(subject)\n",
    "      \n",
    "    # if there is more than one pair of magnitude images (e1+e2),\n",
    "    # take the first one as they are likely to be closer to the fMRI acquisition\n",
    "#    elif len(GREs) > 2:\n",
    "#        print(subject, \"\\n\", \"More than 2 GRE_FIELD sequences\",\n",
    "#              \"(\"+str(len(GREs))+\")\", \".... select only first two for TE extraction\", \"\\n\")\n",
    "\n",
    "\n",
    "## control presence of other relevant file content (presence of condition onset times, covariates of interest etc.)\n",
    "# read relevant content\n",
    "ID_cre=pd.read_excel(credentials, sheet_name=\"analysis\", usecols=['Sub Num FED_XXX'])\n",
    "ID_mod=pd.read_excel(modelinfo, sheet_name=\"analysis\", usecols=['Sub Num FED_XXX'])\n",
    "# bring content to list\n",
    "ID_cre=ID_cre['Sub Num FED_XXX'].tolist()\n",
    "ID_mod=ID_mod['Sub Num FED_XXX'].tolist()\n",
    "# model values are not unique (onset timings -> multiple entries^^) -> FIX for subject ID control \n",
    "ID_mod=list(set(ID_mod))\n",
    "# now for the control\n",
    "for subject,cre,mod in zip_longest(FEDs,ID_cre,ID_mod):\n",
    "    if subject[-1] != cre != mod:\n",
    "        print(\"subject(s) missing!\")\n",
    "        print(\"First line of list-alignment:  \",subject,f\"FED00{cre}\",f\"FED00{mod}\")\n",
    "        print(\"Control relevant files!\")\n",
    "        # control, but assume that the smaller value has to be eliminated,\n",
    "        # because, apparently, there are no values for it in (at least) one data file\n",
    "        FEDexcl=set(sorted([int(subject[-1]),cre,mod])[:-1])\n",
    "        FEDexcl=[f\"FED00{i}\" for i in FEDexcl]\n",
    "        # exclude respective subjects' functionals and structurals\n",
    "        EPI_excluded.extend(FEDexcl)\n",
    "        T1_excluded.extend(FEDexcl)\n",
    "        break\n",
    "\n",
    "## exclude FEDs based on file criteria\n",
    "print(\"\\n\\n\", \"The following subjects where excluded from further analysis due to false file numbers or missing data: \",\\\n",
    "      \"\\n\", \"EPI: \", sorted(EPI_excluded), \"T1: \", sorted(T1_excluded))\n",
    "\n",
    "## update FEDs based on prior exclusion\n",
    "FEDs=[sub for sub in FEDs if sub not in T1_excluded and sub not in EPI_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new subject list afer initial data and image file checkup:\n",
      "\n",
      "['FED007', 'FED008', 'FED009', 'FED010', 'FED011', 'FED012', 'FED013', 'FED014', 'FED015', 'FED016', 'FED017', 'FED018', 'FED019', 'FED020', 'FED021', 'FED022', 'FED023', 'FED024', 'FED025', 'FED026', 'FED027', 'FED028', 'FED029', 'FED030', 'FED031', 'FED032', 'FED033', 'FED034', 'FED035', 'FED036', 'FED037', 'FED038', 'FED039', 'FED040', 'FED041', 'FED042', 'FED043', 'FED044', 'FED045', 'FED046', 'FED047', 'FED048', 'FED049', 'FED050', 'FED051', 'FED052', 'FED053', 'FED054', 'FED055', 'FED056', 'FED057', 'FED058', 'FED059', 'FED060', 'FED061', 'FED062', 'FED063', 'FED064', 'FED065', 'FED066', 'FED067', 'FED068']\n"
     ]
    }
   ],
   "source": [
    "# control new subject list\n",
    "print(\"The new subject list afer initial data and image file checkup:\\n\")\n",
    "print(FEDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters where not available from subjects' json files: \n",
      " ['FED063_EPI-DwellTime', 'FED064_EPI-DwellTime', 'FED065_EPI-DwellTime', 'FED066_EPI-DwellTime']\n"
     ]
    }
   ],
   "source": [
    "## Read json info data for all relevant parameters\n",
    "# define info of interest\n",
    "#GREspecs=[\"EchoTime\", \"PhaseEncodingDirection\"]\n",
    "EPIspecs=[\"EchoTime\", \"RepetitionTime\", \"EchoTrainLength\", \n",
    "          \"PhaseEncodingSteps\", \"PhaseEncodingDirection\",\n",
    "          \"DwellTime\", \"TotalReadoutTime\", \"EffectiveEchoSpacing\", \"PixelBandwidth\"]\n",
    "T1specs=[\"EchoTime\", \"RepetitionTime\",\n",
    "          \"PhaseEncodingSteps\", \"InversionTime\", \"PixelBandwidth\"]\n",
    "# create list to record missing parameters\n",
    "missing_params=[]\n",
    "\n",
    "# Now for the parameter extraction\n",
    "for subject in FEDs:\n",
    "    # collect relevant files/FED for parameter extraction\n",
    "#    GREs=[file for file in data[subject][\"files\"]\n",
    "#           if re.match(r'(.*(_e1|_e2(?!_ph)).*.json)', file)]\n",
    "    T1s=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(T1_MPRAGE).*.json)', file)]\n",
    "    EPIs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(FMRI).*.json)', file)]\n",
    "\n",
    "    # if there is more than one pair of magnitude images (e1+e2),\n",
    "    # take the first one as they are likely to be closer to the fMRI acquisition\n",
    "#    if len(GREs) > 2:\n",
    "#        print(subject, \"\\n\", \"More than 2 GRE_FIELD sequences\",\n",
    "#              \"(\"+str(len(GREs))+\")\", \".... selecting first two for TE extraction\", \"\\n\")\n",
    "#        GREs = GREs[0:2] \n",
    "    \n",
    "    # T1 PARAMETERS\n",
    "    # collect parameters from the respective scan's json file\n",
    "    for file in T1s:\n",
    "        with open(file) as json_file:\n",
    "            info=json.load(json_file)\n",
    "            for param in T1specs:\n",
    "                # put params into data; use capital letters of parameter name as indicator in key\n",
    "                key=f\"T1_{''.join([char for char in param if char.isupper()])}\"\n",
    "                # if key does not exist -> create list with parameter\n",
    "                if key not in data[subject][\"parameters\"].keys():\n",
    "                    try: data[subject][\"parameters\"][key]=[info[param]]\n",
    "                    # if parameter does not exist in json file -> missing_params\n",
    "                    # append to GRE_excluded\n",
    "                    except KeyError:\n",
    "#                        print(f\"{subject}'s json file does not specify {param}\", \"\\n\",\n",
    "#                             \"noting issue ... \")\n",
    "                        missing_params.append(f\"{subject}_T1-{param}\")\n",
    "                        T1_excluded.append(subject)\n",
    "                        pass\n",
    "                # if key does exist -> append parameter to the list\n",
    "                if key in data[subject][\"parameters\"].keys():\n",
    "                    if info[param] not in data[subject][\"parameters\"][key]:\n",
    "                        data[subject][\"parameters\"][key].append(info[param])\n",
    "                    elif info[param] in data[subject][\"parameters\"][key]:\n",
    "                        pass\n",
    "\n",
    "    # EPI PARAMETERS\n",
    "    # collect parameters from the respective scan's json file\n",
    "    for file in EPIs:\n",
    "        with open(file) as json_file:\n",
    "            info=json.load(json_file)\n",
    "            for param in EPIspecs:\n",
    "                # put params into data; use capital letters of parameter name as indicator in key\n",
    "                key=f\"EPI_{''.join([char for char in param if char.isupper()])}\"\n",
    "                # if key does not exist -> create list with parameter\n",
    "                if key not in data[subject][\"parameters\"].keys():\n",
    "                    try: data[subject][\"parameters\"][key]=[info[param]]\n",
    "                    # if parameter does not exist in json file -> missing_params\n",
    "                    # append to EPI_excluded\n",
    "                    except KeyError:\n",
    "#                        print(f\"{subject}'s json file does not specify {param}\", \"\\n\",\n",
    "#                             \"noting issue ... \")\n",
    "                        missing_params.append(f\"{subject}_EPI-{param}\")\n",
    "                        EPI_excluded.append(subject)\n",
    "                        pass\n",
    "                # if key does exist -> append to the list\n",
    "                if key in data[subject][\"parameters\"].keys():\n",
    "                    if info[param] not in data[subject][\"parameters\"][key]:\n",
    "                        data[subject][\"parameters\"][key].append(info[param])\n",
    "                    elif info[param] in data[subject][\"parameters\"][key]:\n",
    "                        pass\n",
    "\n",
    "## show missing parameters from json files:\n",
    "print(\"The following parameters where not available from subjects' json files:\", \n",
    "      \"\\n\",sorted(missing_params))\n",
    "\n",
    "## exclude FEDs based on file criteria\n",
    "#print(\"\\n\\n\", \"The following subjects where excluded from further analysis due to false file numbers or missing parameters: \",\\\n",
    "#      \"\\n\", \"EPI: \", sorted(EPI_excluded), \"\\n\\n\",\n",
    "#     len(EPI_excluded), \"  subjects in total\")\n",
    "\n",
    "## update FEDs based on prior exclusion\n",
    "#FEDs=[sub for sub in FEDs if sub not in GRE_excluded and sub not in EPI_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit the read-in parameters into analysis format\n",
    "for sub in sorted(FEDs):\n",
    "    # calculate necessary parameters that are not in header information\n",
    "    # deltaTE for GRE_FIELD echo-based comparison\n",
    "#    data[subject][\"parameters\"][\"DeltaTE\"]= reduce(operator.sub, data[subject][\"parameters\"][\"GRE_ET\"])*-1*1000\n",
    "    \n",
    "    # transfer phase encoding directions from field axes to voxel axes\n",
    "    # control field axes values\n",
    "#    print(sub)\n",
    "#    print(data[sub][\"parameters\"][\"EPI_PED\"][0])\n",
    "    epi_phasecodedir=data[sub][\"parameters\"][\"EPI_PED\"][0]\n",
    "    for char in epi_phasecodedir:\n",
    "        if char == \"i\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"x{epi_phasecodedir[1:]}\"\n",
    "        elif char == \"j\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"y{epi_phasecodedir[1:]}\"\n",
    "        elif char == \"k\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"z{epi_phasecodedir[1:]}\"\n",
    "    \n",
    "    # same for T1s\n",
    "#    T1_phasecodedir=data[sub][\"parameters\"][\"T1_PED\"][0]\n",
    "#    for char in T1_phasecodedir:\n",
    "#        if char == \"i\":\n",
    "#            data[sub][\"parameters\"][\"T1_PED\"][0]=f\"x{T1_phasecodedir[1:]}\"\n",
    "#        elif char == \"j\":\n",
    "#            data[sub][\"parameters\"][\"T1_PED\"][0]=f\"y{T1_phasecodedir[1:]}\"\n",
    "#        elif char == \"k\":\n",
    "#            data[sub][\"parameters\"][\"T1_PED\"][0]=f\"z{T1_phasecodedir[1:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control new values\n",
    "# print(data[\"FED015\"][\"parameters\"][\"EPI_PED\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get/create relevant covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create covariates (FSL -> \"EVs\")\n",
    "# get sex, age, depression, latency since clinical episode, severity of clinical episodes, number of clinical episodes, - data from list in .xlsx file(s)\n",
    "\n",
    "# files are already defined ^^\n",
    "# read relevant content\n",
    "content_cre=pd.read_excel(credentials, sheet_name=\"analysis\",\n",
    "                          usecols=['Sub Num FED_XXX','Gender','Age','BDI 22 Score'])\n",
    "content_mod=pd.read_excel(modelinfo, sheet_name=\"analysis\",\n",
    "                          usecols=['Sub Num FED_XXX','Condition','RT','COTcorrect'])\n",
    "\n",
    "# sort panda dataframe according to file sequence in FEDs (account for excluded)\n",
    "# define sort-by list (get FED_ID and format to fit entries in dataframe)\n",
    "model_FED_ID = [i[-3:].lstrip(\"0\") for i in FEDs]\n",
    "# transform values to integers to get values in model_FED_ID\n",
    "model_FED_ID = [np.int(i) for i in model_FED_ID]\n",
    "# define a categorical variable to sort a column and corresponding lines after\n",
    "content_cre['model_FED_ID'] = pd.Categorical(content_cre['Sub Num FED_XXX'],\n",
    "                                             categories = model_FED_ID, ordered=True)\n",
    "# might have to make the sorting here more complex in order to get by-subject by-category sorting !WIP!\n",
    "content_mod['model_FED_ID'] = pd.Categorical(content_mod['Sub Num FED_XXX'],\n",
    "                                             categories = model_FED_ID, ordered=True)\n",
    "# sort dataframe\n",
    "content_cre.sort_values('model_FED_ID', inplace=True)\n",
    "content_mod.sort_values('model_FED_ID', inplace=True)\n",
    "\n",
    "# get relevant covariates\n",
    "dep=content_cre['BDI 22 Score'].tolist()\n",
    "sex=content_cre['Gender'].tolist()\n",
    "age=content_cre['Age'].tolist()\n",
    "cot=content_mod['COTcorrect'].tolist()\n",
    "rt=content_mod['RT'].tolist()\n",
    "condition=content_mod['Condition'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "1                 7       0   21             0            7\n",
      "2                 8       0   18             0            8\n",
      "3                 9       1   18             0            9\n",
      "4                10       1   19             0           10\n",
      "5                11       0   18             1           11\n",
      "6                12       1   19             0           12\n",
      "7                13       0   22             0           13\n",
      "8                14       1   18             1           14\n",
      "9                15       1   18             0           15\n",
      "10               16       1   18             0           16\n",
      "11               17       0   18             0           17\n",
      "12               18       1   18             1           18\n",
      "13               19       0   24             0           19\n",
      "14               20       0   18             0           20\n",
      "15               21       1   18             0           21\n",
      "16               22       0   18             0           22\n",
      "17               23       1   18             0           23\n",
      "18               24       0   22             0           24\n",
      "19               25       1   18             0           25\n",
      "20               26       1   18             0           26\n",
      "21               27       1   19             1           27\n",
      "22               28       1   20             1           28\n",
      "23               29       0   20             1           29\n",
      "24               30       1   19             1           30\n",
      "25               31       1   20             1           31\n",
      "26               32       1   18             1           32\n",
      "27               33       0   18             1           33\n",
      "28               34       1   21             1           34\n",
      "29               35       1   18             1           35\n",
      "30               36       0   21             1           36\n",
      "31               37       1   20             1           37\n",
      "     Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "0                  7          1  302.35   378636.42            7\n",
      "114                7          8  360.94     2992.03            7\n",
      "115                7          8  274.15   140519.27            7\n",
      "116                7          8  304.21   270346.77            7\n",
      "117                7          8  336.39    35819.23            7\n",
      "118                7          8  303.67    38237.89            7\n",
      "119                7          9  265.99   152282.35            7\n",
      "120                7          9  303.02   203887.74            7\n",
      "121                7          9  304.38   294116.45            7\n",
      "113                7          8  325.24   366459.67            7\n",
      "122                7          9  288.47   465091.33            7\n",
      "124                7          9  245.62   122952.07            7\n",
      "125                7          9  344.50   342289.66            7\n",
      "126                7          9  333.27   223074.29            7\n",
      "127                7          9  341.59   324324.79            7\n",
      "128                7          9  365.04   160439.10            7\n",
      "129                7          9  320.63   138116.92            7\n",
      "130                7          9  326.47    65593.88            7\n",
      "131                7          9  365.64   356768.32            7\n",
      "123                7          9  340.78    51198.63            7\n",
      "112                7          8  366.72   220620.79            7\n",
      "111                7          8  330.52   237352.79            7\n",
      "110                7          8  317.37   177211.62            7\n",
      "91                 7          6  338.74   402815.76            7\n",
      "92                 7          6  325.33   448210.69            7\n",
      "93                 7          6  339.58   393223.04            7\n",
      "94                 7          6  228.61    94334.36            7\n",
      "95                 7          6  404.57   388311.10            7\n",
      "96                 7          6  295.56   211028.07            7\n",
      "97                 7          6  325.11   154634.29            7\n",
      "98                 7          6  277.22   133412.31            7\n"
     ]
    }
   ],
   "source": [
    "# control results\n",
    "print(content_cre[0:31])\n",
    "print(content_mod[0:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control results\n",
    "#print(model_FED_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuro] *",
   "language": "python",
   "name": "conda-env-neuro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
