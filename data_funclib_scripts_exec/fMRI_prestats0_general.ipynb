{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather necessary pre-requisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import everything you need\n",
    "from nipype import Node, Workflow\n",
    "import nipype.interfaces.fsl as fsl\n",
    "#import nipype.interfaces.spm as spm\n",
    "#import nibabel as nb\n",
    "from nilearn.plotting import plot_anat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# activate inline magics\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os, operator, re, json, random\n",
    "from functools import reduce\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write update function for file list to data dictionary\n",
    "def update_files():\n",
    "    for sub in FEDs:\n",
    "        # collect image files from source dirs\n",
    "        files=sorted([os.path.join(subdir, content)\n",
    "                      for subdir in FED_dirs\n",
    "                      for content in os.listdir(subdir)\n",
    "                      if re.match(r'(.*.(nii|json))', content)])\n",
    "        # extend content\n",
    "        content=[file for file in files\n",
    "                 if re.match(fr'(.*{sub}.*)', file)]\n",
    "        # update files in data\n",
    "        data[sub][\"files\"]=content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data structure that holds all relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define base diectory for data, fMRI folder structure and FEDs\n",
    "scriptdatadir=\"/home/martin/FED/\"\n",
    "credentials=f\"{scriptdatadir}FED_Subject_Assignments.xlsx\"\n",
    "modelinfo=f\"{scriptdatadir}FED_Day_2_RAW_Coded_ALLCODESFIXED_Kontrolle_Truncated_Correct_and_Incorrect_3SDRemoved_46Fixed.xls\"\n",
    "\n",
    "basedir=\"/fMRI/\"\n",
    "FED_dirs=[os.path.join(basedir, FED) \n",
    "          for FED in os.listdir(basedir)\n",
    "          if os.path.isdir(os.path.join(basedir, FED))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect image files\n",
    "files=sorted([os.path.join(subdir, content)\n",
    "       for subdir in FED_dirs\n",
    "       for content in os.listdir(subdir)\n",
    "       if re.match(r'(.*.(nii|json))', content)])\n",
    "# create a dictionary storing all files/subject\n",
    "data={}\n",
    "for fed in FED_dirs:\n",
    "    ID=fed.rsplit('/', 1)[1]\n",
    "    # define partition for each subject\n",
    "    subject={\"files\":[], \"parameters\":{}}\n",
    "    content=[]\n",
    "    for file in files:\n",
    "        if re.match(fr'(.*{ID}.*)', file):\n",
    "            content.append(file)\n",
    "    subject[\"files\"].extend(content)\n",
    "    data[ID]=subject\n",
    "    \n",
    "# create shortcut to FEDs\n",
    "FEDs=sorted([key for key in data.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get relevant file parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject(s) missing!\n",
      "First line of list-alignment:   FED006 FED006 FED007\n",
      "Control relevant files!\n",
      "\n",
      "\n",
      " The following subjects where excluded from further analysis due to false file numbers or missing data:  \n",
      " EPI:  ['FED006'] T1:  ['FED006']\n"
     ]
    }
   ],
   "source": [
    "## define exclusion set for FEDs that do not meet the requirements\n",
    "#GRE_excluded=[]\n",
    "EPI_excluded=[]\n",
    "T1_excluded=[]\n",
    "\n",
    "## FED control\n",
    "for subject in FEDs:\n",
    "    # collect relevant files/FED for parameter extraction\n",
    "#    GREs=[file for file in data[subject][\"files\"]\n",
    "#           if re.match(r'(.*(_e1|_e2(?!_ph)).*.json)', file)]\n",
    "    EPIs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(FMRI).*.json)', file)]\n",
    "    T1s=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(T1_MPRAGE).*.json)', file)]\n",
    "\n",
    "    # control number of files\n",
    "    if len(EPIs) != 1:\n",
    "        print(subject, \"\\n\", f\"Not exactly one FMRI sequence to read out ({len(EPIs)}).... investigate\", \"\\n\")\n",
    "        EPI_excluded.append(subject)\n",
    "\n",
    "    if len(T1s) != 1:\n",
    "        print(subject, \"\\n\", f\"Not exactly one T1 sequence to read out ({len(T1)}).... investigate\", \"\\n\")\n",
    "        T1_excluded.append(subject)    \n",
    "\n",
    "    # There seem to be several omissions in the GRER_FIELD data -> investigate\n",
    "#    elif len(GREs) < 2:\n",
    "#        print(subject, \"\\n\", f\"Not enough GRE_FIELD sequences to read out ({len(GREs)}).... exclude/investigate\", \"\\n\")\n",
    "#        GRE_excluded.append(subject)\n",
    "      \n",
    "    # if there is more than one pair of magnitude images (e1+e2),\n",
    "    # take the first one as they are likely to be closer to the fMRI acquisition\n",
    "#    elif len(GREs) > 2:\n",
    "#        print(subject, \"\\n\", \"More than 2 GRE_FIELD sequences\",\n",
    "#              \"(\"+str(len(GREs))+\")\", \".... select only first two for TE extraction\", \"\\n\")\n",
    "\n",
    "\n",
    "## control presence of other relevant file content (presence of condition onset times, covariates of interest etc.)\n",
    "# read relevant content\n",
    "ID_cre=pd.read_excel(credentials, sheet_name=\"analysis\", usecols=['Sub Num FED_XXX'])\n",
    "ID_mod=pd.read_excel(modelinfo, sheet_name=\"analysis\", usecols=['Sub Num FED_XXX'])\n",
    "# bring content to list\n",
    "ID_cre=ID_cre['Sub Num FED_XXX'].tolist()\n",
    "ID_mod=ID_mod['Sub Num FED_XXX'].tolist()\n",
    "# model values are not unique (onset timings -> multiple entries^^) -> FIX for subject ID control \n",
    "ID_mod=list(set(ID_mod))\n",
    "# now for the control\n",
    "for subject,cre,mod in zip_longest(FEDs,ID_cre,ID_mod):\n",
    "    if subject[-1] != cre != mod:\n",
    "        print(\"subject(s) missing!\")\n",
    "        print(\"First line of list-alignment:  \",subject,f\"FED00{cre}\",f\"FED00{mod}\")\n",
    "        print(\"Control relevant files!\")\n",
    "        # control, but assume that the smaller value has to be eliminated,\n",
    "        # because, apparently, there are no values for it in (at least) one data file\n",
    "        FEDexcl=set(sorted([int(subject[-1]),cre,mod])[:-1])\n",
    "        FEDexcl=[f\"FED00{i}\" for i in FEDexcl]\n",
    "        # exclude respective subjects' functionals and structurals\n",
    "        EPI_excluded.extend(FEDexcl)\n",
    "        T1_excluded.extend(FEDexcl)\n",
    "        break\n",
    "\n",
    "## exclude FEDs based on file criteria\n",
    "print(\"\\n\\n\", \"The following subjects where excluded from further analysis due to false file numbers or missing data: \",\\\n",
    "      \"\\n\", \"EPI: \", sorted(EPI_excluded), \"T1: \", sorted(T1_excluded))\n",
    "\n",
    "## update data and FEDs based on prior exclusion\n",
    "[data.pop(sub) for sub in FEDs if sub in T1_excluded and sub in EPI_excluded]\n",
    "FEDs=[sub for sub in FEDs if sub not in T1_excluded and sub not in EPI_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new subject list afer initial data and image file checkup:\n",
      "\n",
      "['FED007', 'FED008', 'FED009', 'FED010', 'FED011', 'FED012', 'FED013', 'FED014', 'FED015', 'FED016', 'FED017', 'FED018', 'FED019', 'FED020', 'FED021', 'FED022', 'FED023', 'FED024', 'FED025', 'FED026', 'FED027', 'FED028', 'FED029', 'FED030', 'FED031', 'FED032', 'FED033', 'FED034', 'FED035', 'FED036', 'FED037', 'FED038', 'FED039', 'FED040', 'FED041', 'FED042', 'FED043', 'FED044', 'FED045', 'FED046', 'FED047', 'FED048', 'FED049', 'FED050', 'FED051', 'FED052', 'FED053', 'FED054', 'FED055', 'FED056', 'FED057', 'FED058', 'FED059', 'FED060', 'FED061', 'FED062', 'FED063', 'FED064', 'FED065', 'FED066', 'FED067', 'FED068']\n"
     ]
    }
   ],
   "source": [
    "# control new subject list\n",
    "print(\"The new subject list afer initial data and image file checkup:\\n\")\n",
    "print(FEDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters where not available from subjects' json files: \n",
      " ['FED063_EPI-DwellTime', 'FED064_EPI-DwellTime', 'FED065_EPI-DwellTime', 'FED066_EPI-DwellTime']\n"
     ]
    }
   ],
   "source": [
    "## Read json info data for all relevant parameters\n",
    "# define info of interest\n",
    "#GREspecs=[\"EchoTime\", \"PhaseEncodingDirection\"]\n",
    "EPIspecs=[\"EchoTime\", \"RepetitionTime\", \"EchoTrainLength\", \n",
    "          \"PhaseEncodingSteps\", \"PhaseEncodingDirection\",\n",
    "          \"DwellTime\", \"TotalReadoutTime\", \"EffectiveEchoSpacing\", \"PixelBandwidth\"]\n",
    "T1specs=[\"EchoTime\", \"RepetitionTime\",\n",
    "          \"PhaseEncodingSteps\", \"InversionTime\", \"PixelBandwidth\"]\n",
    "# create list to record missing parameters\n",
    "missing_params=[]\n",
    "\n",
    "# Now for the parameter extraction\n",
    "for subject in FEDs:\n",
    "    # collect relevant files/FED for parameter extraction\n",
    "#    GREs=[file for file in data[subject][\"files\"]\n",
    "#           if re.match(r'(.*(_e1|_e2(?!_ph)).*.json)', file)]\n",
    "    T1s=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(T1_MPRAGE).*.json)', file)]\n",
    "    EPIs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(FMRI).*.json)', file)]\n",
    "\n",
    "    # if there is more than one pair of magnitude images (e1+e2),\n",
    "    # take the first one as they are likely to be closer to the fMRI acquisition\n",
    "#    if len(GREs) > 2:\n",
    "#        print(subject, \"\\n\", \"More than 2 GRE_FIELD sequences\",\n",
    "#              \"(\"+str(len(GREs))+\")\", \".... selecting first two for TE extraction\", \"\\n\")\n",
    "#        GREs = GREs[0:2] \n",
    "    \n",
    "    # T1 PARAMETERS\n",
    "    # collect parameters from the respective scan's json file\n",
    "    for file in T1s:\n",
    "        with open(file) as json_file:\n",
    "            info=json.load(json_file)\n",
    "            for param in T1specs:\n",
    "                # put params into data; use capital letters of parameter name as indicator in key\n",
    "                key=f\"T1_{''.join([char for char in param if char.isupper()])}\"\n",
    "                # if key does not exist -> create list with parameter\n",
    "                if key not in data[subject][\"parameters\"].keys():\n",
    "                    try: data[subject][\"parameters\"][key]=[info[param]]\n",
    "                    # if parameter does not exist in json file -> missing_params\n",
    "                    # append to GRE_excluded\n",
    "                    except KeyError:\n",
    "#                        print(f\"{subject}'s json file does not specify {param}\", \"\\n\",\n",
    "#                             \"noting issue ... \")\n",
    "                        missing_params.append(f\"{subject}_T1-{param}\")\n",
    "                        T1_excluded.append(subject)\n",
    "                        pass\n",
    "                # if key does exist -> append parameter to the list\n",
    "                if key in data[subject][\"parameters\"].keys():\n",
    "                    if info[param] not in data[subject][\"parameters\"][key]:\n",
    "                        data[subject][\"parameters\"][key].append(info[param])\n",
    "                    elif info[param] in data[subject][\"parameters\"][key]:\n",
    "                        pass\n",
    "\n",
    "    # EPI PARAMETERS\n",
    "    # collect parameters from the respective scan's json file\n",
    "    for file in EPIs:\n",
    "        with open(file) as json_file:\n",
    "            info=json.load(json_file)\n",
    "            for param in EPIspecs:\n",
    "                # put params into data; use capital letters of parameter name as indicator in key\n",
    "                key=f\"EPI_{''.join([char for char in param if char.isupper()])}\"\n",
    "                # if key does not exist -> create list with parameter\n",
    "                if key not in data[subject][\"parameters\"].keys():\n",
    "                    try: data[subject][\"parameters\"][key]=[info[param]]\n",
    "                    # if parameter does not exist in json file -> missing_params\n",
    "                    # append to EPI_excluded\n",
    "                    except KeyError:\n",
    "#                        print(f\"{subject}'s json file does not specify {param}\", \"\\n\",\n",
    "#                             \"noting issue ... \")\n",
    "                        missing_params.append(f\"{subject}_EPI-{param}\")\n",
    "                        EPI_excluded.append(subject)\n",
    "                        pass\n",
    "                # if key does exist -> append to the list\n",
    "                if key in data[subject][\"parameters\"].keys():\n",
    "                    if info[param] not in data[subject][\"parameters\"][key]:\n",
    "                        data[subject][\"parameters\"][key].append(info[param])\n",
    "                    elif info[param] in data[subject][\"parameters\"][key]:\n",
    "                        pass\n",
    "\n",
    "## show missing parameters from json files:\n",
    "print(\"The following parameters where not available from subjects' json files:\", \n",
    "      \"\\n\",sorted(missing_params))\n",
    "\n",
    "## exclude FEDs based on file criteria\n",
    "#print(\"\\n\\n\", \"The following subjects where excluded from further analysis due to false file numbers or missing parameters: \",\\\n",
    "#      \"\\n\", \"EPI: \", sorted(EPI_excluded), \"\\n\\n\",\n",
    "#     len(EPI_excluded), \"  subjects in total\")\n",
    "\n",
    "## update data and FEDs based on prior exclusion\n",
    "#[data.pop(sub) for sub in FEDs if sub in T1_excluded and sub in EPI_excluded]\n",
    "#FEDs=[sub for sub in FEDs if sub not in T1_excluded and sub not in EPI_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit the read-in parameters into analysis format\n",
    "for sub in sorted(FEDs):\n",
    "    # calculate necessary parameters that are not in header information\n",
    "    # deltaTE for GRE_FIELD echo-based comparison\n",
    "#    data[subject][\"parameters\"][\"DeltaTE\"]= reduce(operator.sub, data[subject][\"parameters\"][\"GRE_ET\"])*-1*1000\n",
    "    \n",
    "    # transfer phase encoding directions from field axes to voxel axes\n",
    "    # control field axes values\n",
    "#    print(sub)\n",
    "#    print(data[sub][\"parameters\"][\"EPI_PED\"][0])\n",
    "    epi_phasecodedir=data[sub][\"parameters\"][\"EPI_PED\"][0]\n",
    "    for char in epi_phasecodedir:\n",
    "        if char == \"i\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"x{epi_phasecodedir[1:]}\"\n",
    "        elif char == \"j\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"y{epi_phasecodedir[1:]}\"\n",
    "        elif char == \"k\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"z{epi_phasecodedir[1:]}\"\n",
    "    \n",
    "    # same for T1s\n",
    "#    T1_phasecodedir=data[sub][\"parameters\"][\"T1_PED\"][0]\n",
    "#    for char in T1_phasecodedir:\n",
    "#        if char == \"i\":\n",
    "#            data[sub][\"parameters\"][\"T1_PED\"][0]=f\"x{T1_phasecodedir[1:]}\"\n",
    "#        elif char == \"j\":\n",
    "#            data[sub][\"parameters\"][\"T1_PED\"][0]=f\"y{T1_phasecodedir[1:]}\"\n",
    "#        elif char == \"k\":\n",
    "#            data[sub][\"parameters\"][\"T1_PED\"][0]=f\"z{T1_phasecodedir[1:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control new values\n",
    "# print(data[\"FED015\"][\"parameters\"][\"EPI_PED\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get/create relevant covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create covariates (FSL -> \"EVs\")\n",
    "# get sex, age, depression, latency since clinical episode, severity of clinical episodes, number of clinical episodes, - data from list in .xlsx file(s)\n",
    "\n",
    "# files are already defined ^^\n",
    "# read relevant content\n",
    "content_cre=pd.read_excel(credentials, sheet_name=\"analysis\",\n",
    "                          usecols=['Sub Num FED_XXX','Gender','Age','BDI 22 Score'])\n",
    "content_mod=pd.read_excel(modelinfo, sheet_name=\"analysis\",\n",
    "                          usecols=['Sub Num FED_XXX','Condition','RT','COTcorrect'])\n",
    "\n",
    "# sort panda dataframe according to file sequence in FEDs (account for excluded)\n",
    "# define sort-by list (get FED_ID and format to fit entries in dataframe)\n",
    "model_FED_ID = [i[-3:].lstrip(\"0\") for i in FEDs]\n",
    "# transform values to integers to get values in model_FED_ID\n",
    "model_FED_ID = [np.int(i) for i in model_FED_ID]\n",
    "# define a categorical variable to sort a column and corresponding lines after\n",
    "content_cre['model_FED_ID'] = pd.Categorical(content_cre['Sub Num FED_XXX'],\n",
    "                                             categories = model_FED_ID, ordered=True)\n",
    "content_mod['model_FED_ID'] = pd.Categorical(content_mod['Sub Num FED_XXX'],\n",
    "                                             categories = model_FED_ID, ordered=True)\n",
    "# sort dataframes\n",
    "content_cre.sort_values(['model_FED_ID'], inplace=True)\n",
    "content_mod.sort_values(['model_FED_ID','Condition','COTcorrect'], inplace=True)\n",
    "\n",
    "# split experimental data by subject and create separate dataframes for each\n",
    "for sub,datasub in zip(FEDs, model_FED_ID):\n",
    "    # add the dataframe as additional item into subject's parameter dict\n",
    "    data[sub][\"parameters\"][\"covariates\"] = content_cre[content_cre['model_FED_ID'] == datasub]\n",
    "    data[sub][\"parameters\"][\"modelparams\"] = content_mod[content_mod['model_FED_ID'] == datasub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataframes from the xls/xlsx files for each subject:\n",
      "\n",
      "\n",
      "   Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "1                7       0   21             0            7\n",
      "     Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "0                  7          1  302.35   378636.42            7\n",
      "1                  7          1  256.12   373815.76            7\n",
      "2                  7          1  285.54   398061.11            7\n",
      "3                  7          1  303.62   417496.80            7\n",
      "4                  7          1  266.26   364107.72            7\n",
      "..               ...        ...     ...         ...          ...\n",
      "173                7         12  317.89   172440.29            7\n",
      "174                7         12  229.12    92015.77            7\n",
      "175                7         12  282.97    56069.33            7\n",
      "176                7         12  289.26   182049.69            7\n",
      "177                7         12  278.64   115795.06            7\n",
      "\n",
      "[178 rows x 5 columns]\n",
      "   Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "2                8       0   18             0            8\n",
      "     Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "178                8          1  322.03    73600.54            8\n",
      "179                8          1  338.02   186153.26            8\n",
      "180                8          1  306.22   348211.29            8\n",
      "181                8          1  347.89   176460.43            8\n",
      "182                8          1  294.32   225409.60            8\n",
      "..               ...        ...     ...         ...          ...\n",
      "351                8         12  264.76   426542.82            8\n",
      "352                8         12  323.98   340938.60            8\n",
      "353                8         12  334.14   416951.54            8\n",
      "354                8         12  328.60    36803.38            8\n",
      "355                8         12  337.03   362723.31            8\n",
      "\n",
      "[178 rows x 5 columns]\n",
      "   Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "3                9       1   18             0            9\n",
      "     Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "356                9          1  315.42   329045.39            9\n",
      "357                9          1  248.50     8746.81            9\n",
      "358                9          1  282.02   285589.19            9\n",
      "359                9          1  313.45   242390.31            9\n",
      "360                9          1  402.82   280784.49            9\n",
      "..               ...        ...     ...         ...          ...\n",
      "527                9         12  273.38    54601.45            9\n",
      "528                9         12  410.41   360754.98            9\n",
      "529                9         12  226.71    56970.08            9\n",
      "530                9         12  400.71   163791.88            9\n",
      "531                9         12  255.75   249562.91            9\n",
      "\n",
      "[176 rows x 5 columns]\n",
      "   Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "4               10       1   19             0           10\n",
      "     Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "532               10          1  297.33   437180.93           10\n",
      "533               10          1  277.27   332944.16           10\n",
      "534               10          1  395.74   108596.20           10\n",
      "535               10          1  246.95   434845.31           10\n",
      "536               10          1  304.64   216746.14           10\n",
      "..               ...        ...     ...         ...          ...\n",
      "704               10         12  278.14    58063.37           10\n",
      "705               10         12  296.79   277686.22           10\n",
      "706               10         12  336.91   223819.73           10\n",
      "707               10         12  267.20   164876.14           10\n",
      "708               10         12  252.87    79901.42           10\n",
      "\n",
      "[177 rows x 5 columns]\n",
      "   Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "5               11       0   18             1           11\n",
      "     Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "709               11          1  461.50   339187.12           11\n",
      "710               11          1  276.66   168278.93           11\n",
      "711               11          1  331.71   390421.33           11\n",
      "712               11          1  327.49   341739.23           11\n",
      "713               11          1  283.30    90044.10           11\n",
      "..               ...        ...     ...         ...          ...\n",
      "883               11         12  302.85    73377.79           11\n",
      "884               11         12  236.69   404902.17           11\n",
      "885               11         12  351.68   240839.03           11\n",
      "886               11         12  274.60   366042.70           11\n",
      "887               11         12  333.09   236001.68           11\n",
      "\n",
      "[179 rows x 5 columns]\n",
      "   Sub Num FED_XXX  Gender  Age  BDI 22 Score model_FED_ID\n",
      "6               12       1   19             0           12\n",
      "      Sub Num FED_XXX  Condition      RT  COTcorrect model_FED_ID\n",
      "888                12          1  320.16   123509.23           12\n",
      "889                12          1  313.54   293717.81           12\n",
      "890                12          1  261.29     7812.73           12\n",
      "891                12          1  322.63   186528.44           12\n",
      "892                12          1  296.69   396470.15           12\n",
      "...               ...        ...     ...         ...          ...\n",
      "1061               12         12  325.09      540.00           12\n",
      "1062               12         12  267.96    79455.83           12\n",
      "1063               12         12  286.59   358121.51           12\n",
      "1064               12         12  258.65   148296.57           12\n",
      "1065               12         12  319.26   339038.93           12\n",
      "\n",
      "[178 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# total number of onsets seems to vary +-2 -> control results\n",
    "#print(\"The current dataframes from the xls/xlsx files for each subject:\\n\\n\")\n",
    "#for sub,datasub in zip(FEDs[0:6], model_FED_ID[0:6]):\n",
    "#    print(data[sub][\"parameters\"][\"covariates\"])\n",
    "#    print(data[sub][\"parameters\"][\"modelparams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control results\n",
    "#print(model_FED_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuro] *",
   "language": "python",
   "name": "conda-env-neuro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
