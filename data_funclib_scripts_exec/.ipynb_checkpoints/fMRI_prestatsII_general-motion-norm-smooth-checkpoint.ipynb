{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather necessary pre-requisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything you need\n",
    "from nipype import Node, Workflow\n",
    "import nipype.interfaces.fsl as fsl\n",
    "#import nipype.interfaces.spm as spm\n",
    "#import nibabel as nb\n",
    "#from nilearn.plotting import plot_anat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# activate inline magics\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os, operator, re, json, random\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write update function for file list to data dictionary\n",
    "def update_files():\n",
    "    for sub in FEDs:\n",
    "        # collect image files from source dirs\n",
    "        files=sorted([os.path.join(subdir, content)\n",
    "                      for subdir in FED_dirs\n",
    "                      for content in os.listdir(subdir)\n",
    "                      if re.match(r'(.*.(nii|json))', content)])\n",
    "        # extend content\n",
    "        content=[file for file in files\n",
    "                 if re.match(fr'(.*{sub}.*)', file)]\n",
    "        # update files in data\n",
    "        data[sub][\"files\"]=content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base diectory for fMRI folder structure and FEDs\n",
    "basedir=\"/fMRI/\"\n",
    "FED_dirs=[os.path.join(basedir, FED) \n",
    "          for FED in os.listdir(basedir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect image files\n",
    "files=sorted([os.path.join(subdir, content)\n",
    "       for subdir in FED_dirs\n",
    "       for content in os.listdir(subdir)\n",
    "       if re.match(r'(.*.(nii|json))', content)])\n",
    "# create a dictionary storing all files/subject\n",
    "data={}\n",
    "for fed in FED_dirs:\n",
    "    ID=fed.rsplit('/', 1)[1]\n",
    "    # define partition for each subject\n",
    "    subject={\"files\":[], \"parameters\":{}}\n",
    "    content=[]\n",
    "    for file in files:\n",
    "        if re.match(fr'(.*{ID}.*)', file):\n",
    "            content.append(file)\n",
    "    subject[\"files\"].extend(content)\n",
    "    data[ID]=subject\n",
    "    \n",
    "# create shortcut to FEDs\n",
    "FEDs=[key for key in data.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get relevant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FED047 \n",
      " Not enough GRE_FIELD sequences to read out (0).... exclude/investigate \n",
      "\n",
      "FED037 \n",
      " Not enough GRE_FIELD sequences to read out (0).... exclude/investigate \n",
      "\n",
      "FED006 \n",
      " Not enough GRE_FIELD sequences to read out (0).... exclude/investigate \n",
      "\n",
      "FED022 \n",
      " More than 2 GRE_FIELD sequences (4) .... select only first two for TE extraction \n",
      "\n",
      "FED067 \n",
      " Not enough GRE_FIELD sequences to read out (0).... exclude/investigate \n",
      "\n",
      "FED008 \n",
      " Not enough GRE_FIELD sequences to read out (0).... exclude/investigate \n",
      "\n",
      "FED023 \n",
      " More than 2 GRE_FIELD sequences (4) .... select only first two for TE extraction \n",
      "\n",
      "FED029 \n",
      " Not enough GRE_FIELD sequences to read out (0).... exclude/investigate \n",
      "\n",
      "\n",
      "\n",
      " The following subjects where excluded from distortion correction due to false file numbers:  \n",
      " GRE:  ['FED006', 'FED008', 'FED029', 'FED037', 'FED047', 'FED067'] EPI:  []\n"
     ]
    }
   ],
   "source": [
    "# define exclusion set for FEDs that do not meet the requirements\n",
    "GRE_excluded=[]\n",
    "EPI_excluded=[]\n",
    "\n",
    "# FED control\n",
    "for subject in FEDs:\n",
    "    # collect relevant files/FED for parameter extraction\n",
    "    GREs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(_e1|_e2(?!_ph)).*.json)', file)]\n",
    "    EPIs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(FMRI).*.json)', file)]\n",
    "    # control number of files\n",
    "    # There seem to be several omissions -> investigate\n",
    "    if len(GREs) < 2:\n",
    "        print(subject, \"\\n\", f\"Not enough GRE_FIELD sequences to read out ({len(GREs)}).... exclude/investigate\", \"\\n\")\n",
    "        GRE_excluded.append(subject)\n",
    "      \n",
    "    # if there is more than one pair of magnitude images (e1+e2),\n",
    "    # take the first one as they are likely to be closer to the fMRI acquisition\n",
    "    elif len(GREs) > 2:\n",
    "        print(subject, \"\\n\", \"More than 2 GRE_FIELD sequences\",\n",
    "              \"(\"+str(len(GREs))+\")\", \".... select only first two for TE extraction\", \"\\n\")\n",
    "    \n",
    "    elif len(EPIs) != 1:\n",
    "            print(subject, \"\\n\", f\"Not exactly one FMRI sequence to read out ({len(EPIs)}).... investigate\", \"\\n\")\n",
    "            EPI_excluded.append(subject)\n",
    "\n",
    "# exclude FEDs from distortion correction\n",
    "print(\"\\n\\n\", \"The following subjects where excluded from distortion correction due to false file numbers: \",\\\n",
    "      \"\\n\", \"GRE: \", sorted(GRE_excluded), \"EPI: \", sorted(EPI_excluded))\n",
    "\n",
    "# make new list for calculating fieldmaps\n",
    "FEDs=[sub for sub in FEDs if sub not in GRE_excluded and sub not in EPI_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FED015\n",
      "FED012\n",
      "FED030\n",
      "FED054\n",
      "FED042\n",
      "FED024\n",
      "FED038\n",
      "FED045\n",
      "FED061\n",
      "FED035\n",
      "FED022\n",
      "FED022 \n",
      " More than 2 GRE_FIELD sequences (4) .... selecting first two for TE extraction \n",
      "\n",
      "FED009\n",
      "FED036\n",
      "FED019\n",
      "FED017\n",
      "FED053\n",
      "FED043\n",
      "FED055\n",
      "FED058\n",
      "FED066\n",
      "FED066's json file does not specify DwellTime \n",
      " noting issue ... \n",
      "FED021\n",
      "FED056\n",
      "FED027\n",
      "FED020\n",
      "FED048\n",
      "FED026\n",
      "FED016\n",
      "FED013\n",
      "FED031\n",
      "FED039\n",
      "FED025\n",
      "FED023\n",
      "FED023 \n",
      " More than 2 GRE_FIELD sequences (4) .... selecting first two for TE extraction \n",
      "\n",
      "FED044\n",
      "FED057\n",
      "FED064\n",
      "FED064's json file does not specify DwellTime \n",
      " noting issue ... \n",
      "FED010\n",
      "FED065\n",
      "FED065's json file does not specify DwellTime \n",
      " noting issue ... \n",
      "FED068\n",
      "FED014\n",
      "FED033\n",
      "FED063\n",
      "FED063's json file does not specify DwellTime \n",
      " noting issue ... \n",
      "FED050\n",
      "FED040\n",
      "FED062\n",
      "FED052\n",
      "FED034\n",
      "FED007\n",
      "FED041\n",
      "FED028\n",
      "FED011\n",
      "FED059\n",
      "FED049\n",
      "FED046\n",
      "FED032\n",
      "FED018\n",
      "FED051\n",
      "FED060\n",
      "The following parameters where not available from subjects' json files: \n",
      " ['FED063_DwellTime', 'FED064_DwellTime', 'FED065_DwellTime', 'FED066_DwellTime']\n",
      "\n",
      "\n",
      " The following subjects where excluded from distortion correction due to flase file numbers or missing parameters:  \n",
      " GRE:  ['FED006', 'FED008', 'FED029', 'FED037', 'FED047', 'FED067'] EPI:  ['FED063', 'FED064', 'FED065', 'FED066'] \n",
      " 10   subjects in total\n"
     ]
    }
   ],
   "source": [
    "# Read json info data for all relevant parameters\n",
    "# define info of interest\n",
    "GREspecs=[\"EchoTime\", \"PhaseEncodingDirection\"]\n",
    "EPIspecs=[\"EchoTime\", \"RepetitionTime\", \"EchoTrainLength\", \n",
    "          \"PhaseEncodingSteps\", \"PhaseEncodingDirection\",\n",
    "          \"DwellTime\", \"TotalReadoutTime\", \"EffectiveEchoSpacing\", \"PixelBandwidth\"]\n",
    "# create list to record missing parameters\n",
    "missing_params=[]\n",
    "\n",
    "# Now for the parameter extraction\n",
    "for subject in FEDs:\n",
    "    # collect relevant files/FED for parameter extraction\n",
    "    GREs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(_e1|_e2(?!_ph)).*.json)', file)]\n",
    "    EPIs=[file for file in data[subject][\"files\"]\n",
    "           if re.match(r'(.*(FMRI).*.json)', file)]\n",
    "    \n",
    "    # if there is more than one pair of magnitude images (e1+e2),\n",
    "    # take the first one as they are likely to be closer to the fMRI acquisition\n",
    "    if len(GREs) > 2:\n",
    "        print(subject, \"\\n\", \"More than 2 GRE_FIELD sequences\",\n",
    "              \"(\"+str(len(GREs))+\")\", \".... selecting first two for TE extraction\", \"\\n\")\n",
    "        GREs = GREs[0:2] \n",
    "    \n",
    "    # GRE PARAMETERS\n",
    "    # collect parameters from the respective echoe's json file\n",
    "    for file in GREs:\n",
    "        with open(file) as json_file:\n",
    "            info=json.load(json_file)\n",
    "            for param in GREspecs:\n",
    "                # put params into data; use capital letters of parameter name as indicator in key\n",
    "                key=f\"GRE_{''.join([char for char in param if char.isupper()])}\"\n",
    "                # if key does not exist -> create list with parameter\n",
    "                if key not in data[subject][\"parameters\"].keys():\n",
    "                    try: data[subject][\"parameters\"][key]=[info[param]]\n",
    "                    # if parameter does not exist in json file -> missing_params\n",
    "                    # append to GRE_excluded\n",
    "                    except KeyError:\n",
    "                        print(f\"{subject}'s json file does not specify {param}\", \"\\n\",\n",
    "                             \"noting issue ... \")\n",
    "                        missing_params.append(f\"{subject}_{param}\")\n",
    "                        GRE_excluded.append(subject)\n",
    "                        pass\n",
    "                # if key does exist -> append parameter to the list\n",
    "                if key in data[subject][\"parameters\"].keys():\n",
    "                    if info[param] not in data[subject][\"parameters\"][key]:\n",
    "                        data[subject][\"parameters\"][key].append(info[param])\n",
    "                    elif info[param] in data[subject][\"parameters\"][key]:\n",
    "                        pass\n",
    "\n",
    "    # EPI PARAMETERS\n",
    "    # collect parameters from the respective scans\n",
    "    for file in EPIs:\n",
    "        with open(file) as json_file:\n",
    "            info=json.load(json_file)\n",
    "            for param in EPIspecs:\n",
    "                # put params into data; use capital letters of parameter name as indicator in key\n",
    "                key=f\"EPI_{''.join([char for char in param if char.isupper()])}\"\n",
    "                # if key does not exist -> create list with parameter\n",
    "                if key not in data[subject][\"parameters\"].keys():\n",
    "                    try: data[subject][\"parameters\"][key]=[info[param]]\n",
    "                    # if parameter does not exist in json file -> missing_params\n",
    "                    # append to EPI_excluded\n",
    "                    except KeyError:\n",
    "                        print(f\"{subject}'s json file does not specify {param}\", \"\\n\",\n",
    "                             \"noting issue ... \")\n",
    "                        missing_params.append(f\"{subject}_{param}\")\n",
    "                        EPI_excluded.append(subject)\n",
    "                        pass\n",
    "                # if key does exist -> append to the list\n",
    "                if key in data[subject][\"parameters\"].keys():\n",
    "                    if info[param] not in data[subject][\"parameters\"][key]:\n",
    "                        data[subject][\"parameters\"][key].append(info[param])\n",
    "                    elif info[param] in data[subject][\"parameters\"][key]:\n",
    "                        pass\n",
    "\n",
    "# show missing parameters from json files:\n",
    "print(\"The following parameters where not available from subjects' json files:\", \n",
    "      \"\\n\",sorted(missing_params))\n",
    "\n",
    "# exclude FEDs from distortion correction\n",
    "print(\"\\n\\n\", \"The following subjects where excluded from distortion correction due to flase file numbers or missing parameters: \",\\\n",
    "      \"\\n\", \"GRE: \", sorted(GRE_excluded), \"EPI: \", sorted(EPI_excluded), \"\\n\",\n",
    "     len(GRE_excluded)+len(EPI_excluded), \"  subjects in total\")\n",
    "\n",
    "# make new list for calculating fieldmaps\n",
    "FEDs=[sub for sub in FEDs if sub not in GRE_excluded and sub not in EPI_excluded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FED007\n",
      "j-\n",
      "y-\n",
      "FED009\n",
      "j-\n",
      "y-\n",
      "FED010\n",
      "j-\n",
      "y-\n",
      "FED011\n",
      "j-\n",
      "y-\n",
      "FED012\n",
      "j-\n",
      "y-\n",
      "FED013\n",
      "j-\n",
      "y-\n",
      "FED014\n",
      "j-\n",
      "y-\n",
      "FED015\n",
      "j-\n",
      "y-\n",
      "FED016\n",
      "j-\n",
      "y-\n",
      "FED017\n",
      "j-\n",
      "y-\n",
      "FED018\n",
      "i\n",
      "x\n",
      "FED019\n",
      "j-\n",
      "y-\n",
      "FED020\n",
      "i\n",
      "x\n",
      "FED021\n",
      "i\n",
      "x\n",
      "FED022\n",
      "i\n",
      "x\n",
      "FED023\n",
      "i\n",
      "x\n",
      "FED024\n",
      "i\n",
      "x\n",
      "FED025\n",
      "i\n",
      "x\n",
      "FED026\n",
      "j-\n",
      "y-\n",
      "FED027\n",
      "j-\n",
      "y-\n",
      "FED028\n",
      "j-\n",
      "y-\n",
      "FED030\n",
      "j-\n",
      "y-\n",
      "FED031\n",
      "j-\n",
      "y-\n",
      "FED032\n",
      "j-\n",
      "y-\n",
      "FED033\n",
      "i\n",
      "x\n",
      "FED034\n",
      "j-\n",
      "y-\n",
      "FED035\n",
      "j-\n",
      "y-\n",
      "FED036\n",
      "j-\n",
      "y-\n",
      "FED038\n",
      "j-\n",
      "y-\n",
      "FED039\n",
      "j-\n",
      "y-\n",
      "FED040\n",
      "j-\n",
      "y-\n",
      "FED041\n",
      "j-\n",
      "y-\n",
      "FED042\n",
      "j-\n",
      "y-\n",
      "FED043\n",
      "j-\n",
      "y-\n",
      "FED044\n",
      "j-\n",
      "y-\n",
      "FED045\n",
      "j-\n",
      "y-\n",
      "FED046\n",
      "j-\n",
      "y-\n",
      "FED048\n",
      "j-\n",
      "y-\n",
      "FED049\n",
      "j-\n",
      "y-\n",
      "FED050\n",
      "j-\n",
      "y-\n",
      "FED051\n",
      "j-\n",
      "y-\n",
      "FED052\n",
      "j-\n",
      "y-\n",
      "FED053\n",
      "j-\n",
      "y-\n",
      "FED054\n",
      "j-\n",
      "y-\n",
      "FED055\n",
      "j-\n",
      "y-\n",
      "FED056\n",
      "j-\n",
      "y-\n",
      "FED057\n",
      "j-\n",
      "y-\n",
      "FED058\n",
      "j-\n",
      "y-\n",
      "FED059\n",
      "j-\n",
      "y-\n",
      "FED060\n",
      "j-\n",
      "y-\n",
      "FED061\n",
      "j-\n",
      "y-\n",
      "FED062\n",
      "j-\n",
      "y-\n",
      "FED068\n",
      "j-\n",
      "y-\n"
     ]
    }
   ],
   "source": [
    "# Edit the read-in parameters into analysis format\n",
    "for sub in sorted(FEDs):\n",
    "    # calculate necessary parameters that are not in header information\n",
    "    # deltaTE\n",
    "    data[subject][\"parameters\"][\"DeltaTE\"]= reduce(operator.sub, data[subject][\"parameters\"][\"GRE_ET\"])*-1*1000\n",
    "    \n",
    "    # transfer phase encoding directions from field axes to voxel axes\n",
    "    # control field axes values\n",
    "#    print(sub)\n",
    "#    print(data[sub][\"parameters\"][\"EPI_PED\"][0])\n",
    "    epi_phasecodedir=data[sub][\"parameters\"][\"EPI_PED\"][0]\n",
    "    for char in epi_phasecodedir:\n",
    "        if char == \"i\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"x{epi_phasecodedir[1:]}\"\n",
    "        elif char == \"j\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"y{epi_phasecodedir[1:]}\"\n",
    "        elif char == \"k\":\n",
    "            data[sub][\"parameters\"][\"EPI_PED\"][0]=f\"z{epi_phasecodedir[1:]}\"\n",
    "    # control new values\n",
    "#    print(data[sub][\"parameters\"][\"EPI_PED\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'files': ['/fMRI/FED067/FMRI_0007_20160311133810_7.json', '/fMRI/FED067/FMRI_0007_20160311133810_7.nii', '/fMRI/FED067/T1_MPRAGE_0005_20160311133810.json', '/fMRI/FED067/T1_MPRAGE_0005_20160311133810.nii'], 'parameters': {}}\n",
      "{'files': ['/fMRI/FED012/FMRI_FS_0010_20141124150148_10.json', '/fMRI/FED012/FMRI_FS_0010_20141124150148_10.nii', '/fMRI/FED012/GRE_FIELD_MAPPING_0006_20141124150148_e1.json', '/fMRI/FED012/GRE_FIELD_MAPPING_0006_20141124150148_e1.nii', '/fMRI/FED012/GRE_FIELD_MAPPING_0006_20141124150148_e2.json', '/fMRI/FED012/GRE_FIELD_MAPPING_0006_20141124150148_e2.nii', '/fMRI/FED012/GRE_FIELD_MAPPING_0007_20141124150148_e2_ph.json', '/fMRI/FED012/GRE_FIELD_MAPPING_0007_20141124150148_e2_ph.nii', '/fMRI/FED012/GRE_e1mag_bet_B.nii', '/fMRI/FED012/GRE_e1mag_bet_B_mask.nii', '/fMRI/FED012/GRE_fieldmap.nii', '/fMRI/FED012/T1_MPRAGE_0005_20141124150148.json', '/fMRI/FED012/T1_MPRAGE_0005_20141124150148.nii'], 'parameters': {'GRE_ET': [0.00492, 0.00738], 'GRE_PED': ['i'], 'EPI_ET': [0.025], 'EPI_RT': [1.8], 'EPI_ETL': [33], 'EPI_PES': [67], 'EPI_PED': ['y-'], 'EPI_DT': [3e-06], 'EPI_TRT': [0.01742], 'EPI_EES': [0.00026], 'EPI_PB': [2315]}}\n"
     ]
    }
   ],
   "source": [
    "# control results in a random fashion\n",
    "key= random.sample(data.keys(), 1)\n",
    "print(data[key[0]])\n",
    "print(data[\"FED012\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion correct / realign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicetime correction (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will omit this step as advised by Poldrack, Nichols and Mumford \"Handbook of fMRI data analysis\"(2011)\\\n",
    "TR= 1800ms  > 2seconds, interleaved acquisition\\\n",
    "event related analysis is relatively robust to slice-timing problems here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuro] *",
   "language": "python",
   "name": "conda-env-neuro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
